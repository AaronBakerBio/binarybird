{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. First we will load in the training and test data, which has been prepared via band_pass etc to reduce background noise and has had the mfcc, rms, and spec centroid taken as features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6a83947589e8305"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-04T18:14:29.025545Z",
     "start_time": "2024-11-04T18:14:27.880283300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  # Linear and RBF SVM\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression  # Linear/Logistic Regression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "r_state = 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Now we will initialize our full set of ten models and test different hyperparametres"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ba400e5802b0603"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "models_and_grids = [\n",
    "    (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}),\n",
    "    (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}),\n",
    "    (GaussianProcessClassifier(), {'max_iter_predict': [100, 200]}),\n",
    "    (DecisionTreeClassifier(), {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]}),\n",
    "    (RandomForestClassifier(), {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}),\n",
    "    (MLPClassifier(), {'hidden_layer_sizes': [(50,), (100,)], 'learning_rate': ['constant', 'adaptive']}),\n",
    "    (GaussianNB(), {}),\n",
    "    (QuadraticDiscriminantAnalysis(), {}),\n",
    "    (LogisticRegression(), {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}),\n",
    "    (AdaBoostClassifier(), {'n_estimators': [50, 100], 'learning_rate': [0.5, 1]})\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T18:14:29.167032Z",
     "start_time": "2024-11-04T18:14:29.151398900Z"
    }
   },
   "id": "ff412d3dfa5c437a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Test and compare models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb4cfb209eeed26"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier completed: Avg AUROC=0.9934393784252094, Avg Accuracy=0.9804933998768269, Time=1.81 seconds\n",
      "SVC completed: Avg AUROC=N/A, Avg Accuracy=0.9995105237395987, Time=2.37 seconds\n",
      "GaussianProcessClassifier completed: Avg AUROC=0.5024702498953383, Avg Accuracy=0.9525869800801655, Time=19.20 seconds\n",
      "DecisionTreeClassifier completed: Avg AUROC=0.9957777506602573, Avg Accuracy=0.9956032634600628, Time=0.17 seconds\n",
      "RandomForestClassifier completed: Avg AUROC=0.999918896999189, Avg Accuracy=0.9965779410790279, Time=2.42 seconds\n",
      "MLPClassifier completed: Avg AUROC=0.9991889699918897, Avg Accuracy=0.998531571218796, Time=4.26 seconds\n",
      "GaussianNB completed: Avg AUROC=0.9991638103849928, Avg Accuracy=0.9975526186979933, Time=0.05 seconds\n",
      "QuadraticDiscriminantAnalysis completed: Avg AUROC=0.9982624113475178, Avg Accuracy=0.9985358461206335, Time=0.08 seconds\n",
      "LogisticRegression completed: Avg AUROC=1.0, Avg Accuracy=0.9995105237395987, Time=0.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier completed: Avg AUROC=1.0, Avg Accuracy=0.9970674173394293, Time=6.12 seconds\n",
      "\n",
      "--- Top 3 Models by Speed ---\n",
      "GaussianNB - Best Params: {}, Time: 0.05s\n",
      "QuadraticDiscriminantAnalysis - Best Params: {}, Time: 0.08s\n",
      "LogisticRegression - Best Params: {'C': 0.1, 'solver': 'liblinear'}, Time: 0.16s\n",
      "\n",
      "Best AUROC Model: LogisticRegression with AUROC=1.0, Params={'C': 0.1, 'solver': 'liblinear'}\n",
      "Best Accuracy Model: SVC with Accuracy=0.9995105237395987, Params={'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "num_folds = 9\n",
    "gkf = GroupKFold(n_splits=num_folds)\n",
    "best_auc_model = None\n",
    "best_accuracy_model = None\n",
    "fastest_models = []\n",
    "results = []\n",
    "save_dir = r\"C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\fully_extracted_data\"\n",
    "\n",
    "# Load only the training data and group information\n",
    "x_train = np.load(os.path.join(save_dir, 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "group_train = np.load(os.path.join(save_dir, 'group_train.npy'))\n",
    "top_models = []\n",
    "top_params = []\n",
    "\n",
    "# Iterate over each model and parameter grid\n",
    "for model, param_grid in models_and_grids:\n",
    "    model_name = model.__class__.__name__\n",
    "    start_time = time.time()\n",
    "    \n",
    "    fold_aucs = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Set up GroupKFold with GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=gkf.split(x_train, y_train, groups=group_train), scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    try:\n",
    "        # Fit GridSearchCV on the full training set\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Track best models and parameters\n",
    "        top_models.append(best_model)\n",
    "        top_params.append(best_params)\n",
    "\n",
    "        # GroupKFold evaluation with the best parameters\n",
    "        for train_idx, val_idx in gkf.split(x_train, y_train, groups=group_train):\n",
    "            x_fold_train, x_fold_val = x_train[train_idx], x_train[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            # Fit on train fold\n",
    "            best_model.fit(x_fold_train, y_fold_train)\n",
    "            y_val_pred = best_model.predict(x_fold_val)\n",
    "            \n",
    "            # Calculate AUC if applicable\n",
    "            if hasattr(best_model, \"predict_proba\"):\n",
    "                y_val_probs = best_model.predict_proba(x_fold_val)[:, 1]\n",
    "                auc = roc_auc_score(y_fold_val, y_val_probs) if len(np.unique(y_fold_val)) > 1 else \"N/A\"\n",
    "                fold_aucs.append(auc)\n",
    "            else:\n",
    "                fold_aucs.append(\"N/A\")\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_fold_val, y_val_pred)\n",
    "            fold_accuracies.append(accuracy)\n",
    "\n",
    "        # Average AUC and accuracy across folds\n",
    "        avg_auc = np.mean([auc for auc in fold_aucs if auc != \"N/A\"]) if \"N/A\" not in fold_aucs else \"N/A\"\n",
    "        avg_accuracy = np.mean(fold_accuracies)\n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "        # Store results for the model\n",
    "        results.append((model_name, avg_auc, avg_accuracy, run_time, best_params))\n",
    "        \n",
    "        # Track the best models by AUROC and accuracy\n",
    "        if avg_auc != \"N/A\" and (best_auc_model is None or avg_auc > best_auc_model[1]):\n",
    "            best_auc_model = (model_name, avg_auc, best_params)\n",
    "        \n",
    "        if best_accuracy_model is None or avg_accuracy > best_accuracy_model[1]:\n",
    "            best_accuracy_model = (model_name, avg_accuracy, best_params)\n",
    "        \n",
    "        # Track the three fastest models\n",
    "        fastest_models.append((model_name, run_time))\n",
    "        fastest_models = sorted(fastest_models, key=lambda x: x[1])[:3]\n",
    "        \n",
    "        print(f\"{model_name} completed: Avg AUROC={avg_auc}, Avg Accuracy={avg_accuracy}, Time={run_time:.2f} seconds\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Print summary of the top 3 models and their parameters\n",
    "print(\"\\n--- Top 3 Models by Speed ---\")\n",
    "for model_name, run_time in fastest_models:\n",
    "    best_params = next((params for (name, _, _, _, params) in results if name == model_name), {})\n",
    "    print(f\"{model_name} - Best Params: {best_params}, Time: {run_time:.2f}s\")\n",
    "\n",
    "# Print the best models by AUROC and accuracy\n",
    "if best_auc_model:\n",
    "    print(f\"\\nBest AUROC Model: {best_auc_model[0]} with AUROC={best_auc_model[1]}, Params={best_auc_model[2]}\")\n",
    "if best_accuracy_model:\n",
    "    print(f\"Best Accuracy Model: {best_accuracy_model[0]} with Accuracy={best_accuracy_model[1]}, Params={best_accuracy_model[2]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T18:15:16.098771200Z",
     "start_time": "2024-11-04T18:14:39.441731600Z"
    }
   },
   "id": "cda7a147bb6b5639"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap between training and test groups.\n"
     ]
    }
   ],
   "source": [
    "# Assuming group_train and group_test are your group labels for training and test sets\n",
    "save_dir = r\"C:\\Users\\fasta\\PycharmProjects\\binarybird\\venv\\fully_extracted_data\"\n",
    "group_train = np.load(os.path.join(save_dir, 'group_train.npy'))\n",
    "group_test = np.load(os.path.join(save_dir, 'group_test.npy'))\n",
    "\n",
    "# Convert group labels to sets for comparison\n",
    "train_groups = set(np.unique(group_train))  # Unique group identifiers in the training set\n",
    "test_groups = set(np.unique(group_test))     # Unique group identifiers in the test set\n",
    "\n",
    "# Print any common group identifiers\n",
    "overlap_groups = train_groups.intersection(test_groups)\n",
    "if overlap_groups:\n",
    "    print(f\"Overlap found between training and test groups: {overlap_groups}\")\n",
    "else:\n",
    "    print(\"No overlap between training and test groups.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T18:15:16.161216900Z",
     "start_time": "2024-11-04T18:15:16.098771200Z"
    }
   },
   "id": "69ca59d64f9af187"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Results on "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6516359379be2911"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB - Test AUROC: 0.9981858748462163, Test Accuracy: 0.9984\n",
      "QuadraticDiscriminantAnalysis - Test AUROC: 1.0, Test Accuracy: 1.0000\n",
      "LogisticRegression - Test AUROC: 1.0, Test Accuracy: 1.0000\n",
      "\n",
      "--- Summary of Test Results ---\n",
      "GaussianNB: AUROC=0.9981858748462163, Accuracy=0.9984\n",
      "QuadraticDiscriminantAnalysis: AUROC=1.0, Accuracy=1.0000\n",
      "LogisticRegression: AUROC=1.0, Accuracy=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "x_test = np.load(os.path.join(save_dir, 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Initialize a list to hold the results for the top models on the test set\n",
    "test_results = []\n",
    "\n",
    "# Iterate over the top 3 models\n",
    "for model_name, _ in fastest_models:\n",
    "    # Retrieve the best parameters for the current model\n",
    "    best_params = next((params for (name, _, _, _, params) in results if name == model_name), {})\n",
    "    # Initialize the model with the best parameters\n",
    "    model_class = next((m for m, _ in models_and_grids if m.__class__.__name__ == model_name))\n",
    "    best_model = model_class.set_params(**best_params)\n",
    "    # Retrain the model on the entire training set\n",
    "    best_model.fit(x_train, y_train)\n",
    "    # Evaluate the model on the test set\n",
    "    y_test_pred = best_model.predict(x_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    # Calculate AUROC if applicable\n",
    "    if hasattr(best_model, \"predict_proba\"):\n",
    "        y_test_probs = best_model.predict_proba(x_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_test_probs) if len(np.unique(y_test)) > 1 else \"N/A\"\n",
    "    else:\n",
    "        auc = \"N/A\"\n",
    "    # Store the results for this model\n",
    "    test_results.append((model_name, auc, accuracy))\n",
    "    # Print the results\n",
    "    print(f\"{model_name} - Test AUROC: {auc}, Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\n--- Summary of Test Results ---\")\n",
    "for model_name, auc, accuracy in test_results:\n",
    "    print(f\"{model_name}: AUROC={auc}, Accuracy={accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T18:15:16.161216900Z",
     "start_time": "2024-11-04T18:15:16.114328300Z"
    }
   },
   "id": "8e9c9eab8bd04566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "397bfccb8de7e377"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
